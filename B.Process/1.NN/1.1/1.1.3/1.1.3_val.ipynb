{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "folder_name = os.path.basename(current_directory)\n",
    "number = folder_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:23.846948400Z",
     "start_time": "2024-12-26T09:02:23.828390400Z"
    }
   },
   "id": "98e9eccdccd5addd",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_main': 'C:/Users/Николай/PycharmProjects/CIBMTR/D.Data/main/',\n",
    "    'data_train_process': 'C:/Users/Николай/PycharmProjects/CIBMTR/D.Data/train_process/',\n",
    "    'data_train_split': 'C:/Users/Николай/PycharmProjects/CIBMTR/D.Data/train_split/',\n",
    "    'train_path': 'train.csv',\n",
    "    'folds_path': 'v1.csv', \n",
    "\n",
    "    'DEVICE' : 'cuda',\n",
    "    'SEED' : 42,\n",
    "    'BATCH_SIZE' : 32,\n",
    "    'LR' : 0.001,\n",
    "    'EPOCHS': 7,\n",
    "    'output_dim' : 1\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:23.862949700Z",
     "start_time": "2024-12-26T09:02:23.847949500Z"
    }
   },
   "id": "4a794a5c2901e728",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ee4882",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:17.459651Z",
     "iopub.status.busy": "2024-11-25T04:46:17.459331Z",
     "iopub.status.idle": "2024-11-25T04:46:22.363731Z",
     "shell.execute_reply": "2024-11-25T04:46:22.362971Z"
    },
    "papermill": {
     "duration": 4.91114,
     "end_time": "2024-11-25T04:46:22.365894",
     "exception": false,
     "start_time": "2024-11-25T04:46:17.454754",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:25.553852400Z",
     "start_time": "2024-12-26T09:02:23.864948500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.init as init\n",
    "from metric import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf61865",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:22.376480Z",
     "iopub.status.busy": "2024-11-25T04:46:22.375606Z",
     "iopub.status.idle": "2024-11-25T04:46:22.445552Z",
     "shell.execute_reply": "2024-11-25T04:46:22.444304Z"
    },
    "papermill": {
     "duration": 0.077688,
     "end_time": "2024-11-25T04:46:22.448120",
     "exception": false,
     "start_time": "2024-11-25T04:46:22.370432",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:26.813087800Z",
     "start_time": "2024-12-26T09:02:25.554765600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Device, torch decimal places and seed for reproducibility\n",
    "device = torch.device(CONFIG['DEVICE'] if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(precision=40) \n",
    "\n",
    "torch.manual_seed(CONFIG['SEED'])  \n",
    "torch.cuda.manual_seed_all(CONFIG['SEED'])  \n",
    "np.random.seed(CONFIG['SEED'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead528618a5bd413",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:27.116566800Z",
     "start_time": "2024-12-26T09:02:26.815089700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "train = pd.read_csv(f\"{CONFIG['data_main']}{CONFIG['train_path']}\")\n",
    "train = train.fillna('-1')\n",
    "\n",
    "for col in ['donor_age', 'age_at_hct']:\n",
    "    train[col] = train[col].astype(int)\n",
    "    \n",
    "train[\"y\"] = train.efs_time.values\n",
    "mx = train.loc[train.efs==1,\"efs_time\"].max()\n",
    "mn = train.loc[train.efs==0,\"efs_time\"].min()\n",
    "train.loc[train.efs==0,\"y\"] = train.loc[train.efs==0,\"y\"] + mx - mn\n",
    "train.y = train.y.rank()\n",
    "train.loc[train.efs==0,\"y\"] += 2*len(train)\n",
    "train.y = train.y / train.y.max()\n",
    "train.y = np.log( train.y )\n",
    "train.y -= train.y.mean()\n",
    "train.y *= -1.0\n",
    "\n",
    "# train['efs_time'] = (train['efs_time'] - train['efs_time'].min()) / (train['efs_time'].max() - train['efs_time'].min())\n",
    "\n",
    "cat_columns = [col for col in train.columns if col not in ['efs', 'efs_time', 'y', 'ID']]\n",
    "train[cat_columns] = train[cat_columns].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "folds = pd.read_csv(f\"{CONFIG['data_train_split']}{CONFIG['folds_path']}\")\n",
    "val = train[folds['fold'] == 4].copy(deep=True)\n",
    "train = train[folds['fold'].isin([0, 1, 2, 3])].copy(deep=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:22.463105Z",
     "iopub.status.busy": "2024-11-25T04:46:22.462120Z",
     "iopub.status.idle": "2024-11-25T04:46:36.958670Z",
     "shell.execute_reply": "2024-11-25T04:46:36.957928Z"
    },
    "papermill": {
     "duration": 14.504329,
     "end_time": "2024-11-25T04:46:36.960715",
     "exception": false,
     "start_time": "2024-11-25T04:46:22.456386",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:27.209059400Z",
     "start_time": "2024-12-26T09:02:27.120548300Z"
    }
   },
   "id": "3dfa6723",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_one_hot = pd.get_dummies(train[cat_columns], drop_first=True)\n",
    "val_one_hot = pd.get_dummies(val[cat_columns], drop_first=True)\n",
    "val_one_hot = val_one_hot.reindex(columns=train_one_hot.columns, fill_value=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:27.354160900Z",
     "start_time": "2024-12-26T09:02:27.210058500Z"
    }
   },
   "id": "a4023592ce465a05",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_dim = train_one_hot.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:27.370156Z",
     "start_time": "2024-12-26T09:02:27.356175Z"
    }
   },
   "id": "7203f96cf36f7ac0",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=CONFIG['output_dim']):\n",
    "        super(Model, self).__init__()\n",
    "    \n",
    "        self.fc1 = nn.Linear(input_dim, input_dim // 2)\n",
    "        self.fc2 = nn.Linear(input_dim // 2, input_dim // 4)\n",
    "        self.fc3 = nn.Linear(input_dim // 4, output_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.do = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        init.xavier_uniform_(self.fc1.weight)\n",
    "        init.xavier_uniform_(self.fc2.weight)\n",
    "        init.xavier_uniform_(self.fc3.weight)\n",
    "    \n",
    "        self.fc1.weight.data = torch.clamp(self.fc1.weight.data, 0, 1)\n",
    "        self.fc2.weight.data = torch.clamp(self.fc2.weight.data, 0, 1)\n",
    "        self.fc3.weight.data = torch.clamp(self.fc3.weight.data, 0, 1)\n",
    "\n",
    "        if self.fc1.bias is not None:\n",
    "            init.zeros_(self.fc1.bias)\n",
    "        if self.fc2.bias is not None:\n",
    "            init.zeros_(self.fc2.bias)\n",
    "        if self.fc3.bias is not None:\n",
    "            init.zeros_(self.fc3.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.do(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.do(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:27.394061600Z",
     "start_time": "2024-12-26T09:02:27.373081500Z"
    }
   },
   "id": "769b210d304532d1",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae46951b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:40.465946Z",
     "iopub.status.busy": "2024-11-25T04:46:40.465691Z",
     "iopub.status.idle": "2024-11-25T04:46:41.656166Z",
     "shell.execute_reply": "2024-11-25T04:46:41.655167Z"
    },
    "papermill": {
     "duration": 1.197018,
     "end_time": "2024-11-25T04:46:41.658294",
     "exception": false,
     "start_time": "2024-11-25T04:46:40.461276",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:28.654082500Z",
     "start_time": "2024-12-26T09:02:27.388135500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model, criterion and optimizer\n",
    "model = Model(input_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=CONFIG['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_tensors = torch.tensor(train_one_hot.values, device=device, dtype=torch.float32)\n",
    "\n",
    "train_targets = torch.tensor(train['y'].values, device=device, dtype=torch.float32)\n",
    "\n",
    "val_tensors = torch.tensor(val_one_hot.values, device=device, dtype=torch.float32)\n",
    "\n",
    "val_targets = torch.tensor(val['y'].values, device=device, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:28.735094900Z",
     "start_time": "2024-12-26T09:02:28.656987800Z"
    }
   },
   "id": "2bed9b1ed476d50a",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9815da53f5d0594f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:44.215575800Z",
     "start_time": "2024-12-26T09:02:28.740091Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/7: 100%|██████████| 720/720 [00:01<00:00, 378.75batch/s, train_mean_loss=18.588293]\n",
      "Epoch 1/7: 100%|██████████| 180/180 [00:00<00:00, 820.67batch/s, val_mean_loss=2.129881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6329182499412365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/7: 100%|██████████| 720/720 [00:01<00:00, 386.70batch/s, train_mean_loss=2.074710]\n",
      "Epoch 2/7: 100%|██████████| 180/180 [00:00<00:00, 877.81batch/s, val_mean_loss=1.971634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6547586703231209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/7: 100%|██████████| 720/720 [00:01<00:00, 408.39batch/s, train_mean_loss=1.935668]\n",
      "Epoch 3/7: 100%|██████████| 180/180 [00:00<00:00, 870.56batch/s, val_mean_loss=1.924696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6616678654811642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/7: 100%|██████████| 720/720 [00:01<00:00, 389.99batch/s, train_mean_loss=1.884340]\n",
      "Epoch 4/7: 100%|██████████| 180/180 [00:00<00:00, 810.48batch/s, val_mean_loss=1.913616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6661412702470068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/7: 100%|██████████| 720/720 [00:01<00:00, 382.94batch/s, train_mean_loss=1.845700]\n",
      "Epoch 5/7: 100%|██████████| 180/180 [00:00<00:00, 861.32batch/s, val_mean_loss=1.906154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6674319116433822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/7: 100%|██████████| 720/720 [00:02<00:00, 341.80batch/s, train_mean_loss=1.830560]\n",
      "Epoch 6/7: 100%|██████████| 180/180 [00:00<00:00, 803.55batch/s, val_mean_loss=1.902106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6695741517000044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/7: 100%|██████████| 720/720 [00:02<00:00, 311.98batch/s, train_mean_loss=1.799513]\n",
      "Epoch 7/7: 100%|██████████| 180/180 [00:00<00:00, 821.95batch/s, val_mean_loss=1.881882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6720195432442079\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_num_samples = len(train)\n",
    "train_num_batches = (train_num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "val_num_samples = len(val)\n",
    "val_num_batches = (val_num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "for epoch in range(CONFIG['EPOCHS']):\n",
    "    ##################################################################TRAIN##################################################################\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "\n",
    "    with tqdm(range(train_num_batches), desc=f\"Epoch {epoch + 1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as t:\n",
    "        for batch_idx in t:\n",
    "            start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "            end_idx = min(start_idx + CONFIG['BATCH_SIZE'], train_num_samples)\n",
    "\n",
    "            # Извлечение батча данных\n",
    "            batch_inputs = train_tensors[start_idx:end_idx]\n",
    "            batch_targets = train_targets[start_idx:end_idx]\n",
    "            \n",
    "            # Обнуление градиентов\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Прямой проход\n",
    "            outputs = model(batch_inputs)\n",
    "\n",
    "            # Вычисление функции потерь\n",
    "            batch_loss = criterion(outputs, batch_targets.unsqueeze(1))\n",
    "\n",
    "            # Обратный проход\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss += batch_loss.item()\n",
    "            t.set_postfix(train_mean_loss=f\"{train_running_loss / (batch_idx + 1):.6f}\")\n",
    "    \n",
    "    ###EVAL\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    \n",
    "    outputs_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(range(val_num_batches), desc=f\"Epoch {epoch + 1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as v:\n",
    "            for batch_idx in v:\n",
    "                start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "                end_idx = min(start_idx + CONFIG['BATCH_SIZE'], val_num_samples)\n",
    "                \n",
    "                batch_inputs = val_tensors[start_idx:end_idx]\n",
    "                batch_targets = val_targets[start_idx:end_idx]\n",
    "    \n",
    "                # Прямой проход\n",
    "                outputs = model(batch_inputs)\n",
    "                \n",
    "                batch_loss = criterion(outputs, batch_targets.unsqueeze(1))\n",
    "                val_running_loss += batch_loss.item()\n",
    "                v.set_postfix(val_mean_loss=f\"{val_running_loss / (batch_idx + 1):.6f}\")\n",
    "        \n",
    "                outputs_list.extend(outputs.cpu().numpy().flatten())\n",
    "    \n",
    "    ###SAVE\n",
    "    row_id_column_name = \"ID\"\n",
    "    y_pred = val[['ID']].copy(deep=True)\n",
    "    y_pred[\"prediction\"] = outputs_list\n",
    "    \n",
    "    y_true = val[['ID', 'efs', 'efs_time', 'race_group']].copy(deep=True)\n",
    "    print(score(y_true.copy(), y_pred.copy(), row_id_column_name))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T09:02:44.229579100Z",
     "start_time": "2024-12-26T09:02:44.215575800Z"
    }
   },
   "id": "5dd66befac09e49e",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6155403,
     "sourceId": 10000346,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5460.653933,
   "end_time": "2024-11-25T06:17:15.604943",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-25T04:46:14.951010",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
