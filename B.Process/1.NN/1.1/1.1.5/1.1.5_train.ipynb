{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "folder_name = os.path.basename(current_directory)\n",
    "number = folder_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T19:04:11.977846500Z",
     "start_time": "2024-12-26T19:04:11.961845700Z"
    }
   },
   "id": "98e9eccdccd5addd",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_main': 'C:/Users/Николай/PycharmProjects/CIBMTR/D.Data/main/',\n",
    "    'train_path': 'train.csv',\n",
    "\n",
    "    'DEVICE' : 'cuda',\n",
    "    'SEED' : 42,\n",
    "    'BATCH_SIZE' : 256,\n",
    "    'LR' : 0.0001,\n",
    "    'EPOCHS': 243,\n",
    "    'output_dim' : 1\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T19:04:12.008844600Z",
     "start_time": "2024-12-26T19:04:11.979845200Z"
    }
   },
   "id": "4a794a5c2901e728",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ee4882",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:17.459651Z",
     "iopub.status.busy": "2024-11-25T04:46:17.459331Z",
     "iopub.status.idle": "2024-11-25T04:46:22.363731Z",
     "shell.execute_reply": "2024-11-25T04:46:22.362971Z"
    },
    "papermill": {
     "duration": 4.91114,
     "end_time": "2024-11-25T04:46:22.365894",
     "exception": false,
     "start_time": "2024-11-25T04:46:17.454754",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-26T19:04:13.353064300Z",
     "start_time": "2024-12-26T19:04:11.993845900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf61865",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:22.376480Z",
     "iopub.status.busy": "2024-11-25T04:46:22.375606Z",
     "iopub.status.idle": "2024-11-25T04:46:22.445552Z",
     "shell.execute_reply": "2024-11-25T04:46:22.444304Z"
    },
    "papermill": {
     "duration": 0.077688,
     "end_time": "2024-11-25T04:46:22.448120",
     "exception": false,
     "start_time": "2024-11-25T04:46:22.370432",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-26T19:04:14.606610700Z",
     "start_time": "2024-12-26T19:04:14.596660Z"
    }
   },
   "outputs": [],
   "source": [
    "# Device, torch decimal places and seed for reproducibility\n",
    "device = torch.device(CONFIG['DEVICE'] if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(precision=40) \n",
    "\n",
    "torch.manual_seed(CONFIG['SEED'])  \n",
    "torch.cuda.manual_seed_all(CONFIG['SEED'])  \n",
    "np.random.seed(CONFIG['SEED'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead528618a5bd413",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T19:04:14.894211700Z",
     "start_time": "2024-12-26T19:04:14.610611100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "train = pd.read_csv(f\"{CONFIG['data_main']}{CONFIG['train_path']}\")\n",
    "train = train.fillna('-1')\n",
    "\n",
    "for col in ['donor_age', 'age_at_hct']:\n",
    "    train[col] = train[col].astype(int)\n",
    "    \n",
    "train[\"y\"] = train.efs_time.values\n",
    "mx = train.loc[train.efs==1,\"efs_time\"].max()\n",
    "mn = train.loc[train.efs==0,\"efs_time\"].min()\n",
    "train.loc[train.efs==0,\"y\"] = train.loc[train.efs==0,\"y\"] + mx - mn\n",
    "train.y = train.y.rank()\n",
    "train.loc[train.efs==0,\"y\"] += 2*len(train)\n",
    "train.y = train.y / train.y.max()\n",
    "train.y = np.log( train.y )\n",
    "train.y -= train.y.mean()\n",
    "train.y *= -1.0\n",
    "\n",
    "cat_columns = [col for col in train.columns if col not in ['efs', 'efs_time', 'y', 'ID']]\n",
    "train[cat_columns] = train[cat_columns].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_one_hot = pd.get_dummies(train[cat_columns], drop_first=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T19:04:15.052353900Z",
     "start_time": "2024-12-26T19:04:14.896256500Z"
    }
   },
   "id": "a4023592ce465a05",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_dim = train_one_hot.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T19:04:15.068320600Z",
     "start_time": "2024-12-26T19:04:15.056351900Z"
    }
   },
   "id": "7203f96cf36f7ac0",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=CONFIG['output_dim']):\n",
    "        super(Model, self).__init__()\n",
    "    \n",
    "        self.fc1 = nn.Linear(input_dim, input_dim)\n",
    "        self.fc2 = nn.Linear(input_dim, input_dim)\n",
    "        self.fc3 = nn.Linear(input_dim, input_dim)\n",
    "        self.fc4 = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.do = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        init.xavier_uniform_(self.fc1.weight)\n",
    "        init.xavier_uniform_(self.fc2.weight)\n",
    "        init.xavier_uniform_(self.fc3.weight)\n",
    "        init.xavier_uniform_(self.fc4.weight)\n",
    "    \n",
    "        self.fc1.weight.data = torch.clamp(self.fc1.weight.data, 0, 1)\n",
    "        self.fc2.weight.data = torch.clamp(self.fc2.weight.data, 0, 1)\n",
    "        self.fc3.weight.data = torch.clamp(self.fc3.weight.data, 0, 1)\n",
    "        self.fc4.weight.data = torch.clamp(self.fc4.weight.data, 0, 1)\n",
    "        \n",
    "        if self.fc1.bias is not None:\n",
    "            init.zeros_(self.fc1.bias)\n",
    "        if self.fc2.bias is not None:\n",
    "            init.zeros_(self.fc2.bias)\n",
    "        if self.fc3.bias is not None:\n",
    "            init.zeros_(self.fc3.bias)\n",
    "        if self.fc4.bias is not None:\n",
    "            init.zeros_(self.fc4.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.do(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.do(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.do(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T19:04:15.085324300Z",
     "start_time": "2024-12-26T19:04:15.074360700Z"
    }
   },
   "id": "769b210d304532d1",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae46951b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:40.465946Z",
     "iopub.status.busy": "2024-11-25T04:46:40.465691Z",
     "iopub.status.idle": "2024-11-25T04:46:41.656166Z",
     "shell.execute_reply": "2024-11-25T04:46:41.655167Z"
    },
    "papermill": {
     "duration": 1.197018,
     "end_time": "2024-11-25T04:46:41.658294",
     "exception": false,
     "start_time": "2024-11-25T04:46:40.461276",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-26T19:04:16.272852Z",
     "start_time": "2024-12-26T19:04:15.087386700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model, criterion and optimizer\n",
    "model = Model(input_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=CONFIG['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_tensors = torch.tensor(train_one_hot.values, device=device, dtype=torch.float32)\n",
    "\n",
    "train_targets = torch.tensor(train['y'].values, device=device, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T19:04:16.352533600Z",
     "start_time": "2024-12-26T19:04:16.275859Z"
    }
   },
   "id": "2bed9b1ed476d50a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9815da53f5d0594f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T19:05:52.555002600Z",
     "start_time": "2024-12-26T19:04:16.354583200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/243: 100%|██████████| 113/113 [00:00<00:00, 258.01batch/s, train_mean_loss=229734.563053]\n",
      "Epoch 2/243: 100%|██████████| 113/113 [00:00<00:00, 326.23batch/s, train_mean_loss=16267.101442]\n",
      "Epoch 3/243: 100%|██████████| 113/113 [00:00<00:00, 318.28batch/s, train_mean_loss=2088.013760]\n",
      "Epoch 4/243: 100%|██████████| 113/113 [00:00<00:00, 343.86batch/s, train_mean_loss=500.903062]\n",
      "Epoch 5/243: 100%|██████████| 113/113 [00:00<00:00, 374.49batch/s, train_mean_loss=399.753890]\n",
      "Epoch 6/243: 100%|██████████| 113/113 [00:00<00:00, 361.02batch/s, train_mean_loss=380.433054]\n",
      "Epoch 7/243: 100%|██████████| 113/113 [00:00<00:00, 384.74batch/s, train_mean_loss=374.153044]\n",
      "Epoch 8/243: 100%|██████████| 113/113 [00:00<00:00, 361.89batch/s, train_mean_loss=367.319121]\n",
      "Epoch 9/243: 100%|██████████| 113/113 [00:00<00:00, 360.64batch/s, train_mean_loss=356.046290]\n",
      "Epoch 10/243: 100%|██████████| 113/113 [00:00<00:00, 364.51batch/s, train_mean_loss=339.034508]\n",
      "Epoch 11/243: 100%|██████████| 113/113 [00:00<00:00, 363.95batch/s, train_mean_loss=329.322455]\n",
      "Epoch 12/243: 100%|██████████| 113/113 [00:00<00:00, 365.74batch/s, train_mean_loss=315.544653]\n",
      "Epoch 13/243: 100%|██████████| 113/113 [00:00<00:00, 370.43batch/s, train_mean_loss=302.527937]\n",
      "Epoch 14/243: 100%|██████████| 113/113 [00:00<00:00, 370.20batch/s, train_mean_loss=295.017654]\n",
      "Epoch 15/243: 100%|██████████| 113/113 [00:00<00:00, 274.88batch/s, train_mean_loss=275.210120]\n",
      "Epoch 16/243: 100%|██████████| 113/113 [00:00<00:00, 371.85batch/s, train_mean_loss=266.462468]\n",
      "Epoch 17/243: 100%|██████████| 113/113 [00:00<00:00, 366.84batch/s, train_mean_loss=256.535820]\n",
      "Epoch 18/243: 100%|██████████| 113/113 [00:00<00:00, 429.74batch/s, train_mean_loss=242.472133]\n",
      "Epoch 19/243: 100%|██████████| 113/113 [00:00<00:00, 459.23batch/s, train_mean_loss=229.177464]\n",
      "Epoch 20/243: 100%|██████████| 113/113 [00:00<00:00, 478.86batch/s, train_mean_loss=220.494318]\n",
      "Epoch 21/243: 100%|██████████| 113/113 [00:00<00:00, 461.39batch/s, train_mean_loss=207.598516]\n",
      "Epoch 22/243: 100%|██████████| 113/113 [00:00<00:00, 472.88batch/s, train_mean_loss=196.791787]\n",
      "Epoch 23/243: 100%|██████████| 113/113 [00:00<00:00, 466.91batch/s, train_mean_loss=188.476023]\n",
      "Epoch 24/243: 100%|██████████| 113/113 [00:00<00:00, 326.59batch/s, train_mean_loss=174.556737]\n",
      "Epoch 25/243: 100%|██████████| 113/113 [00:00<00:00, 347.93batch/s, train_mean_loss=165.947966]\n",
      "Epoch 26/243: 100%|██████████| 113/113 [00:00<00:00, 399.29batch/s, train_mean_loss=156.879458]\n",
      "Epoch 27/243: 100%|██████████| 113/113 [00:00<00:00, 419.93batch/s, train_mean_loss=150.647044]\n",
      "Epoch 28/243: 100%|██████████| 113/113 [00:00<00:00, 422.35batch/s, train_mean_loss=141.439446]\n",
      "Epoch 29/243: 100%|██████████| 113/113 [00:00<00:00, 448.37batch/s, train_mean_loss=129.086991]\n",
      "Epoch 30/243: 100%|██████████| 113/113 [00:00<00:00, 418.13batch/s, train_mean_loss=123.131843]\n",
      "Epoch 31/243: 100%|██████████| 113/113 [00:00<00:00, 459.36batch/s, train_mean_loss=116.015401]\n",
      "Epoch 32/243: 100%|██████████| 113/113 [00:00<00:00, 461.52batch/s, train_mean_loss=110.228457]\n",
      "Epoch 33/243: 100%|██████████| 113/113 [00:00<00:00, 470.74batch/s, train_mean_loss=102.085424]\n",
      "Epoch 34/243: 100%|██████████| 113/113 [00:00<00:00, 466.89batch/s, train_mean_loss=95.387181]\n",
      "Epoch 35/243: 100%|██████████| 113/113 [00:00<00:00, 470.06batch/s, train_mean_loss=88.191173]\n",
      "Epoch 36/243: 100%|██████████| 113/113 [00:00<00:00, 453.27batch/s, train_mean_loss=82.667769]\n",
      "Epoch 37/243: 100%|██████████| 113/113 [00:00<00:00, 455.65batch/s, train_mean_loss=76.472577]\n",
      "Epoch 38/243: 100%|██████████| 113/113 [00:00<00:00, 465.03batch/s, train_mean_loss=73.163259]\n",
      "Epoch 39/243: 100%|██████████| 113/113 [00:00<00:00, 446.58batch/s, train_mean_loss=68.517904]\n",
      "Epoch 40/243: 100%|██████████| 113/113 [00:00<00:00, 451.10batch/s, train_mean_loss=62.958032]\n",
      "Epoch 41/243: 100%|██████████| 113/113 [00:00<00:00, 452.83batch/s, train_mean_loss=59.351758]\n",
      "Epoch 42/243: 100%|██████████| 113/113 [00:00<00:00, 461.23batch/s, train_mean_loss=54.365169]\n",
      "Epoch 43/243: 100%|██████████| 113/113 [00:00<00:00, 363.29batch/s, train_mean_loss=51.398867]\n",
      "Epoch 44/243: 100%|██████████| 113/113 [00:00<00:00, 350.91batch/s, train_mean_loss=47.287524]\n",
      "Epoch 45/243: 100%|██████████| 113/113 [00:00<00:00, 360.55batch/s, train_mean_loss=45.132073]\n",
      "Epoch 46/243: 100%|██████████| 113/113 [00:00<00:00, 310.70batch/s, train_mean_loss=41.579322]\n",
      "Epoch 47/243: 100%|██████████| 113/113 [00:00<00:00, 352.60batch/s, train_mean_loss=38.663051]\n",
      "Epoch 48/243: 100%|██████████| 113/113 [00:00<00:00, 344.52batch/s, train_mean_loss=35.370492]\n",
      "Epoch 49/243: 100%|██████████| 113/113 [00:00<00:00, 360.97batch/s, train_mean_loss=33.753819]\n",
      "Epoch 50/243: 100%|██████████| 113/113 [00:00<00:00, 352.96batch/s, train_mean_loss=31.120440]\n",
      "Epoch 51/243: 100%|██████████| 113/113 [00:00<00:00, 356.40batch/s, train_mean_loss=28.880849]\n",
      "Epoch 52/243: 100%|██████████| 113/113 [00:00<00:00, 354.19batch/s, train_mean_loss=26.855448]\n",
      "Epoch 53/243: 100%|██████████| 113/113 [00:00<00:00, 356.96batch/s, train_mean_loss=25.445772]\n",
      "Epoch 54/243: 100%|██████████| 113/113 [00:00<00:00, 353.78batch/s, train_mean_loss=23.948779]\n",
      "Epoch 55/243: 100%|██████████| 113/113 [00:00<00:00, 356.39batch/s, train_mean_loss=21.884743]\n",
      "Epoch 56/243: 100%|██████████| 113/113 [00:00<00:00, 355.91batch/s, train_mean_loss=20.370038]\n",
      "Epoch 57/243: 100%|██████████| 113/113 [00:00<00:00, 270.97batch/s, train_mean_loss=18.771237]\n",
      "Epoch 58/243: 100%|██████████| 113/113 [00:00<00:00, 359.38batch/s, train_mean_loss=17.931209]\n",
      "Epoch 59/243: 100%|██████████| 113/113 [00:00<00:00, 354.52batch/s, train_mean_loss=16.480850]\n",
      "Epoch 60/243: 100%|██████████| 113/113 [00:00<00:00, 342.55batch/s, train_mean_loss=15.184237]\n",
      "Epoch 61/243: 100%|██████████| 113/113 [00:00<00:00, 357.49batch/s, train_mean_loss=14.235421]\n",
      "Epoch 62/243: 100%|██████████| 113/113 [00:00<00:00, 343.70batch/s, train_mean_loss=13.288199]\n",
      "Epoch 63/243: 100%|██████████| 113/113 [00:00<00:00, 342.40batch/s, train_mean_loss=12.473989]\n",
      "Epoch 64/243: 100%|██████████| 113/113 [00:00<00:00, 297.19batch/s, train_mean_loss=11.584308]\n",
      "Epoch 65/243: 100%|██████████| 113/113 [00:00<00:00, 317.57batch/s, train_mean_loss=10.936413]\n",
      "Epoch 66/243: 100%|██████████| 113/113 [00:00<00:00, 302.95batch/s, train_mean_loss=10.354749]\n",
      "Epoch 67/243: 100%|██████████| 113/113 [00:00<00:00, 305.40batch/s, train_mean_loss=9.638661]\n",
      "Epoch 68/243: 100%|██████████| 113/113 [00:00<00:00, 302.71batch/s, train_mean_loss=9.036799]\n",
      "Epoch 69/243: 100%|██████████| 113/113 [00:00<00:00, 276.90batch/s, train_mean_loss=8.546519]\n",
      "Epoch 70/243: 100%|██████████| 113/113 [00:00<00:00, 282.90batch/s, train_mean_loss=7.947174]\n",
      "Epoch 71/243: 100%|██████████| 113/113 [00:00<00:00, 265.89batch/s, train_mean_loss=7.518702]\n",
      "Epoch 72/243: 100%|██████████| 113/113 [00:00<00:00, 269.26batch/s, train_mean_loss=6.973824]\n",
      "Epoch 73/243: 100%|██████████| 113/113 [00:00<00:00, 302.32batch/s, train_mean_loss=6.739263]\n",
      "Epoch 74/243: 100%|██████████| 113/113 [00:00<00:00, 312.96batch/s, train_mean_loss=6.328537]\n",
      "Epoch 75/243: 100%|██████████| 113/113 [00:00<00:00, 263.16batch/s, train_mean_loss=5.931339]\n",
      "Epoch 76/243: 100%|██████████| 113/113 [00:00<00:00, 325.29batch/s, train_mean_loss=5.719645]\n",
      "Epoch 77/243: 100%|██████████| 113/113 [00:00<00:00, 335.29batch/s, train_mean_loss=5.450814]\n",
      "Epoch 78/243: 100%|██████████| 113/113 [00:00<00:00, 309.78batch/s, train_mean_loss=5.181861]\n",
      "Epoch 79/243: 100%|██████████| 113/113 [00:00<00:00, 332.35batch/s, train_mean_loss=4.931973]\n",
      "Epoch 80/243: 100%|██████████| 113/113 [00:00<00:00, 272.09batch/s, train_mean_loss=4.623184]\n",
      "Epoch 81/243: 100%|██████████| 113/113 [00:00<00:00, 275.42batch/s, train_mean_loss=4.441656]\n",
      "Epoch 82/243: 100%|██████████| 113/113 [00:00<00:00, 236.40batch/s, train_mean_loss=4.254729]\n",
      "Epoch 83/243: 100%|██████████| 113/113 [00:00<00:00, 254.73batch/s, train_mean_loss=4.080744]\n",
      "Epoch 84/243: 100%|██████████| 113/113 [00:00<00:00, 175.48batch/s, train_mean_loss=4.036442]\n",
      "Epoch 85/243: 100%|██████████| 113/113 [00:00<00:00, 203.76batch/s, train_mean_loss=3.821802]\n",
      "Epoch 86/243: 100%|██████████| 113/113 [00:00<00:00, 255.32batch/s, train_mean_loss=3.656261]\n",
      "Epoch 87/243: 100%|██████████| 113/113 [00:00<00:00, 315.57batch/s, train_mean_loss=3.570504]\n",
      "Epoch 88/243: 100%|██████████| 113/113 [00:00<00:00, 260.71batch/s, train_mean_loss=3.446910]\n",
      "Epoch 89/243: 100%|██████████| 113/113 [00:00<00:00, 250.45batch/s, train_mean_loss=3.290917]\n",
      "Epoch 90/243: 100%|██████████| 113/113 [00:00<00:00, 256.24batch/s, train_mean_loss=3.212621]\n",
      "Epoch 91/243: 100%|██████████| 113/113 [00:00<00:00, 214.90batch/s, train_mean_loss=3.151640]\n",
      "Epoch 92/243: 100%|██████████| 113/113 [00:00<00:00, 186.47batch/s, train_mean_loss=3.094052]\n",
      "Epoch 93/243: 100%|██████████| 113/113 [00:00<00:00, 213.96batch/s, train_mean_loss=3.018945]\n",
      "Epoch 94/243: 100%|██████████| 113/113 [00:00<00:00, 209.97batch/s, train_mean_loss=2.965908]\n",
      "Epoch 95/243: 100%|██████████| 113/113 [00:00<00:00, 213.89batch/s, train_mean_loss=2.882478]\n",
      "Epoch 96/243: 100%|██████████| 113/113 [00:00<00:00, 208.10batch/s, train_mean_loss=2.834882]\n",
      "Epoch 97/243: 100%|██████████| 113/113 [00:00<00:00, 196.38batch/s, train_mean_loss=2.741209]\n",
      "Epoch 98/243: 100%|██████████| 113/113 [00:00<00:00, 210.34batch/s, train_mean_loss=2.732910]\n",
      "Epoch 99/243: 100%|██████████| 113/113 [00:00<00:00, 192.18batch/s, train_mean_loss=2.676462]\n",
      "Epoch 100/243: 100%|██████████| 113/113 [00:00<00:00, 209.19batch/s, train_mean_loss=2.648323]\n",
      "Epoch 101/243: 100%|██████████| 113/113 [00:00<00:00, 214.01batch/s, train_mean_loss=2.598217]\n",
      "Epoch 102/243: 100%|██████████| 113/113 [00:00<00:00, 208.39batch/s, train_mean_loss=2.580323]\n",
      "Epoch 103/243: 100%|██████████| 113/113 [00:00<00:00, 215.24batch/s, train_mean_loss=2.555675]\n",
      "Epoch 104/243: 100%|██████████| 113/113 [00:00<00:00, 216.16batch/s, train_mean_loss=2.491947]\n",
      "Epoch 105/243: 100%|██████████| 113/113 [00:00<00:00, 216.06batch/s, train_mean_loss=2.493207]\n",
      "Epoch 106/243: 100%|██████████| 113/113 [00:00<00:00, 215.99batch/s, train_mean_loss=2.476594]\n",
      "Epoch 107/243: 100%|██████████| 113/113 [00:00<00:00, 214.39batch/s, train_mean_loss=2.447963]\n",
      "Epoch 108/243: 100%|██████████| 113/113 [00:00<00:00, 216.82batch/s, train_mean_loss=2.400161]\n",
      "Epoch 109/243: 100%|██████████| 113/113 [00:00<00:00, 178.41batch/s, train_mean_loss=2.399420]\n",
      "Epoch 110/243: 100%|██████████| 113/113 [00:00<00:00, 215.65batch/s, train_mean_loss=2.371762]\n",
      "Epoch 111/243: 100%|██████████| 113/113 [00:00<00:00, 215.58batch/s, train_mean_loss=2.370882]\n",
      "Epoch 112/243: 100%|██████████| 113/113 [00:00<00:00, 217.43batch/s, train_mean_loss=2.351553]\n",
      "Epoch 113/243: 100%|██████████| 113/113 [00:00<00:00, 214.96batch/s, train_mean_loss=2.326896]\n",
      "Epoch 114/243: 100%|██████████| 113/113 [00:00<00:00, 215.24batch/s, train_mean_loss=2.332988]\n",
      "Epoch 115/243: 100%|██████████| 113/113 [00:00<00:00, 213.55batch/s, train_mean_loss=2.316548]\n",
      "Epoch 116/243: 100%|██████████| 113/113 [00:00<00:00, 204.69batch/s, train_mean_loss=2.302944]\n",
      "Epoch 117/243: 100%|██████████| 113/113 [00:00<00:00, 204.59batch/s, train_mean_loss=2.296431]\n",
      "Epoch 118/243: 100%|██████████| 113/113 [00:00<00:00, 217.09batch/s, train_mean_loss=2.285885]\n",
      "Epoch 119/243: 100%|██████████| 113/113 [00:00<00:00, 202.70batch/s, train_mean_loss=2.281099]\n",
      "Epoch 120/243: 100%|██████████| 113/113 [00:00<00:00, 214.21batch/s, train_mean_loss=2.264724]\n",
      "Epoch 121/243: 100%|██████████| 113/113 [00:00<00:00, 217.16batch/s, train_mean_loss=2.250646]\n",
      "Epoch 122/243: 100%|██████████| 113/113 [00:00<00:00, 207.08batch/s, train_mean_loss=2.245435]\n",
      "Epoch 123/243: 100%|██████████| 113/113 [00:00<00:00, 214.06batch/s, train_mean_loss=2.236178]\n",
      "Epoch 124/243: 100%|██████████| 113/113 [00:00<00:00, 216.20batch/s, train_mean_loss=2.221209]\n",
      "Epoch 125/243: 100%|██████████| 113/113 [00:00<00:00, 216.06batch/s, train_mean_loss=2.213499]\n",
      "Epoch 126/243: 100%|██████████| 113/113 [00:00<00:00, 218.47batch/s, train_mean_loss=2.207576]\n",
      "Epoch 127/243: 100%|██████████| 113/113 [00:00<00:00, 216.45batch/s, train_mean_loss=2.191753]\n",
      "Epoch 128/243: 100%|██████████| 113/113 [00:00<00:00, 217.99batch/s, train_mean_loss=2.180798]\n",
      "Epoch 129/243: 100%|██████████| 113/113 [00:00<00:00, 219.83batch/s, train_mean_loss=2.167479]\n",
      "Epoch 130/243: 100%|██████████| 113/113 [00:00<00:00, 216.60batch/s, train_mean_loss=2.157608]\n",
      "Epoch 131/243: 100%|██████████| 113/113 [00:00<00:00, 213.93batch/s, train_mean_loss=2.140745]\n",
      "Epoch 132/243: 100%|██████████| 113/113 [00:00<00:00, 212.49batch/s, train_mean_loss=2.132823]\n",
      "Epoch 133/243: 100%|██████████| 113/113 [00:00<00:00, 207.97batch/s, train_mean_loss=2.117941]\n",
      "Epoch 134/243: 100%|██████████| 113/113 [00:00<00:00, 184.58batch/s, train_mean_loss=2.096896]\n",
      "Epoch 135/243: 100%|██████████| 113/113 [00:00<00:00, 204.87batch/s, train_mean_loss=2.091135]\n",
      "Epoch 136/243: 100%|██████████| 113/113 [00:00<00:00, 204.64batch/s, train_mean_loss=2.070973]\n",
      "Epoch 137/243: 100%|██████████| 113/113 [00:00<00:00, 206.27batch/s, train_mean_loss=2.069153]\n",
      "Epoch 138/243: 100%|██████████| 113/113 [00:00<00:00, 217.09batch/s, train_mean_loss=2.055969]\n",
      "Epoch 139/243: 100%|██████████| 113/113 [00:00<00:00, 219.75batch/s, train_mean_loss=2.039168]\n",
      "Epoch 140/243: 100%|██████████| 113/113 [00:00<00:00, 218.77batch/s, train_mean_loss=2.029027]\n",
      "Epoch 141/243: 100%|██████████| 113/113 [00:00<00:00, 219.76batch/s, train_mean_loss=2.023307]\n",
      "Epoch 142/243: 100%|██████████| 113/113 [00:00<00:00, 217.09batch/s, train_mean_loss=2.004113]\n",
      "Epoch 143/243: 100%|██████████| 113/113 [00:00<00:00, 213.00batch/s, train_mean_loss=2.005757]\n",
      "Epoch 144/243: 100%|██████████| 113/113 [00:00<00:00, 211.61batch/s, train_mean_loss=2.000499]\n",
      "Epoch 145/243: 100%|██████████| 113/113 [00:00<00:00, 219.96batch/s, train_mean_loss=1.981321]\n",
      "Epoch 146/243: 100%|██████████| 113/113 [00:00<00:00, 217.73batch/s, train_mean_loss=1.976330]\n",
      "Epoch 147/243: 100%|██████████| 113/113 [00:00<00:00, 218.71batch/s, train_mean_loss=1.970330]\n",
      "Epoch 148/243: 100%|██████████| 113/113 [00:00<00:00, 221.57batch/s, train_mean_loss=1.961104]\n",
      "Epoch 149/243: 100%|██████████| 113/113 [00:00<00:00, 217.21batch/s, train_mean_loss=1.950730]\n",
      "Epoch 150/243: 100%|██████████| 113/113 [00:00<00:00, 212.94batch/s, train_mean_loss=1.943074]\n",
      "Epoch 151/243: 100%|██████████| 113/113 [00:00<00:00, 234.83batch/s, train_mean_loss=1.941635]\n",
      "Epoch 152/243: 100%|██████████| 113/113 [00:00<00:00, 298.94batch/s, train_mean_loss=1.928735]\n",
      "Epoch 153/243: 100%|██████████| 113/113 [00:00<00:00, 325.43batch/s, train_mean_loss=1.919673]\n",
      "Epoch 154/243: 100%|██████████| 113/113 [00:00<00:00, 359.21batch/s, train_mean_loss=1.920485]\n",
      "Epoch 155/243: 100%|██████████| 113/113 [00:00<00:00, 356.51batch/s, train_mean_loss=1.911076]\n",
      "Epoch 156/243: 100%|██████████| 113/113 [00:00<00:00, 367.25batch/s, train_mean_loss=1.908264]\n",
      "Epoch 157/243: 100%|██████████| 113/113 [00:00<00:00, 355.66batch/s, train_mean_loss=1.904338]\n",
      "Epoch 158/243: 100%|██████████| 113/113 [00:00<00:00, 350.48batch/s, train_mean_loss=1.899322]\n",
      "Epoch 159/243: 100%|██████████| 113/113 [00:00<00:00, 359.83batch/s, train_mean_loss=1.887000]\n",
      "Epoch 160/243: 100%|██████████| 113/113 [00:00<00:00, 314.81batch/s, train_mean_loss=1.885161]\n",
      "Epoch 161/243: 100%|██████████| 113/113 [00:00<00:00, 291.28batch/s, train_mean_loss=1.882398]\n",
      "Epoch 162/243: 100%|██████████| 113/113 [00:00<00:00, 352.26batch/s, train_mean_loss=1.868924]\n",
      "Epoch 163/243: 100%|██████████| 113/113 [00:00<00:00, 325.99batch/s, train_mean_loss=1.861204]\n",
      "Epoch 164/243: 100%|██████████| 113/113 [00:00<00:00, 327.53batch/s, train_mean_loss=1.863747]\n",
      "Epoch 165/243: 100%|██████████| 113/113 [00:00<00:00, 333.37batch/s, train_mean_loss=1.844991]\n",
      "Epoch 166/243: 100%|██████████| 113/113 [00:00<00:00, 335.27batch/s, train_mean_loss=1.844822]\n",
      "Epoch 167/243: 100%|██████████| 113/113 [00:00<00:00, 335.31batch/s, train_mean_loss=1.838226]\n",
      "Epoch 168/243: 100%|██████████| 113/113 [00:00<00:00, 348.13batch/s, train_mean_loss=1.836878]\n",
      "Epoch 169/243: 100%|██████████| 113/113 [00:00<00:00, 334.83batch/s, train_mean_loss=1.832319]\n",
      "Epoch 170/243: 100%|██████████| 113/113 [00:00<00:00, 343.22batch/s, train_mean_loss=1.820293]\n",
      "Epoch 171/243: 100%|██████████| 113/113 [00:00<00:00, 329.72batch/s, train_mean_loss=1.806375]\n",
      "Epoch 172/243: 100%|██████████| 113/113 [00:00<00:00, 339.34batch/s, train_mean_loss=1.807815]\n",
      "Epoch 173/243: 100%|██████████| 113/113 [00:00<00:00, 339.36batch/s, train_mean_loss=1.801035]\n",
      "Epoch 174/243: 100%|██████████| 113/113 [00:00<00:00, 331.19batch/s, train_mean_loss=1.793288]\n",
      "Epoch 175/243: 100%|██████████| 113/113 [00:00<00:00, 300.53batch/s, train_mean_loss=1.780600]\n",
      "Epoch 176/243: 100%|██████████| 113/113 [00:00<00:00, 298.94batch/s, train_mean_loss=1.774509]\n",
      "Epoch 177/243: 100%|██████████| 113/113 [00:00<00:00, 287.15batch/s, train_mean_loss=1.763529]\n",
      "Epoch 178/243: 100%|██████████| 113/113 [00:00<00:00, 342.33batch/s, train_mean_loss=1.748750]\n",
      "Epoch 179/243: 100%|██████████| 113/113 [00:00<00:00, 319.22batch/s, train_mean_loss=1.744234]\n",
      "Epoch 180/243: 100%|██████████| 113/113 [00:00<00:00, 318.39batch/s, train_mean_loss=1.742177]\n",
      "Epoch 181/243: 100%|██████████| 113/113 [00:00<00:00, 324.34batch/s, train_mean_loss=1.732641]\n",
      "Epoch 182/243: 100%|██████████| 113/113 [00:00<00:00, 317.73batch/s, train_mean_loss=1.708430]\n",
      "Epoch 183/243: 100%|██████████| 113/113 [00:00<00:00, 339.72batch/s, train_mean_loss=1.710958]\n",
      "Epoch 184/243: 100%|██████████| 113/113 [00:00<00:00, 296.59batch/s, train_mean_loss=1.703155]\n",
      "Epoch 185/243: 100%|██████████| 113/113 [00:00<00:00, 293.86batch/s, train_mean_loss=1.682433]\n",
      "Epoch 186/243: 100%|██████████| 113/113 [00:00<00:00, 246.18batch/s, train_mean_loss=1.676983]\n",
      "Epoch 187/243: 100%|██████████| 113/113 [00:00<00:00, 331.28batch/s, train_mean_loss=1.649654]\n",
      "Epoch 188/243: 100%|██████████| 113/113 [00:00<00:00, 296.47batch/s, train_mean_loss=1.639731]\n",
      "Epoch 189/243: 100%|██████████| 113/113 [00:00<00:00, 239.41batch/s, train_mean_loss=1.633698]\n",
      "Epoch 190/243: 100%|██████████| 113/113 [00:00<00:00, 234.38batch/s, train_mean_loss=1.610652]\n",
      "Epoch 191/243: 100%|██████████| 113/113 [00:00<00:00, 212.96batch/s, train_mean_loss=1.598647]\n",
      "Epoch 192/243: 100%|██████████| 113/113 [00:00<00:00, 213.14batch/s, train_mean_loss=1.595025]\n",
      "Epoch 193/243: 100%|██████████| 113/113 [00:00<00:00, 216.06batch/s, train_mean_loss=1.571005]\n",
      "Epoch 194/243: 100%|██████████| 113/113 [00:00<00:00, 238.78batch/s, train_mean_loss=1.567168]\n",
      "Epoch 195/243: 100%|██████████| 113/113 [00:00<00:00, 274.23batch/s, train_mean_loss=1.551491]\n",
      "Epoch 196/243: 100%|██████████| 113/113 [00:00<00:00, 351.86batch/s, train_mean_loss=1.538871]\n",
      "Epoch 197/243: 100%|██████████| 113/113 [00:00<00:00, 358.25batch/s, train_mean_loss=1.528018]\n",
      "Epoch 198/243: 100%|██████████| 113/113 [00:00<00:00, 354.24batch/s, train_mean_loss=1.518428]\n",
      "Epoch 199/243: 100%|██████████| 113/113 [00:00<00:00, 357.18batch/s, train_mean_loss=1.494576]\n",
      "Epoch 200/243: 100%|██████████| 113/113 [00:00<00:00, 358.94batch/s, train_mean_loss=1.482417]\n",
      "Epoch 201/243: 100%|██████████| 113/113 [00:00<00:00, 356.37batch/s, train_mean_loss=1.469117]\n",
      "Epoch 202/243: 100%|██████████| 113/113 [00:00<00:00, 350.71batch/s, train_mean_loss=1.453053]\n",
      "Epoch 203/243: 100%|██████████| 113/113 [00:00<00:00, 353.41batch/s, train_mean_loss=1.446300]\n",
      "Epoch 204/243: 100%|██████████| 113/113 [00:00<00:00, 350.93batch/s, train_mean_loss=1.430866]\n",
      "Epoch 205/243: 100%|██████████| 113/113 [00:00<00:00, 345.62batch/s, train_mean_loss=1.417494]\n",
      "Epoch 206/243: 100%|██████████| 113/113 [00:00<00:00, 350.10batch/s, train_mean_loss=1.404229]\n",
      "Epoch 207/243: 100%|██████████| 113/113 [00:00<00:00, 361.01batch/s, train_mean_loss=1.397360]\n",
      "Epoch 208/243: 100%|██████████| 113/113 [00:00<00:00, 348.79batch/s, train_mean_loss=1.376144]\n",
      "Epoch 209/243: 100%|██████████| 113/113 [00:00<00:00, 339.91batch/s, train_mean_loss=1.359745]\n",
      "Epoch 210/243: 100%|██████████| 113/113 [00:00<00:00, 267.44batch/s, train_mean_loss=1.353525]\n",
      "Epoch 211/243: 100%|██████████| 113/113 [00:00<00:00, 347.27batch/s, train_mean_loss=1.347236]\n",
      "Epoch 212/243: 100%|██████████| 113/113 [00:00<00:00, 340.87batch/s, train_mean_loss=1.331828]\n",
      "Epoch 213/243: 100%|██████████| 113/113 [00:00<00:00, 339.70batch/s, train_mean_loss=1.318825]\n",
      "Epoch 214/243: 100%|██████████| 113/113 [00:00<00:00, 352.28batch/s, train_mean_loss=1.301870]\n",
      "Epoch 215/243: 100%|██████████| 113/113 [00:00<00:00, 341.77batch/s, train_mean_loss=1.293271]\n",
      "Epoch 216/243: 100%|██████████| 113/113 [00:00<00:00, 346.60batch/s, train_mean_loss=1.283905]\n",
      "Epoch 217/243: 100%|██████████| 113/113 [00:00<00:00, 347.37batch/s, train_mean_loss=1.274930]\n",
      "Epoch 218/243: 100%|██████████| 113/113 [00:00<00:00, 333.05batch/s, train_mean_loss=1.254773]\n",
      "Epoch 219/243: 100%|██████████| 113/113 [00:00<00:00, 345.53batch/s, train_mean_loss=1.252427]\n",
      "Epoch 220/243: 100%|██████████| 113/113 [00:00<00:00, 340.10batch/s, train_mean_loss=1.237171]\n",
      "Epoch 221/243: 100%|██████████| 113/113 [00:00<00:00, 342.60batch/s, train_mean_loss=1.227911]\n",
      "Epoch 222/243: 100%|██████████| 113/113 [00:00<00:00, 326.09batch/s, train_mean_loss=1.222585]\n",
      "Epoch 223/243: 100%|██████████| 113/113 [00:00<00:00, 337.46batch/s, train_mean_loss=1.208248]\n",
      "Epoch 224/243: 100%|██████████| 113/113 [00:00<00:00, 344.72batch/s, train_mean_loss=1.187782]\n",
      "Epoch 225/243: 100%|██████████| 113/113 [00:00<00:00, 339.26batch/s, train_mean_loss=1.193562]\n",
      "Epoch 226/243: 100%|██████████| 113/113 [00:00<00:00, 352.16batch/s, train_mean_loss=1.178081]\n",
      "Epoch 227/243: 100%|██████████| 113/113 [00:00<00:00, 328.88batch/s, train_mean_loss=1.159936]\n",
      "Epoch 228/243: 100%|██████████| 113/113 [00:00<00:00, 294.32batch/s, train_mean_loss=1.160599]\n",
      "Epoch 229/243: 100%|██████████| 113/113 [00:00<00:00, 285.95batch/s, train_mean_loss=1.153833]\n",
      "Epoch 230/243: 100%|██████████| 113/113 [00:00<00:00, 325.65batch/s, train_mean_loss=1.139623]\n",
      "Epoch 231/243: 100%|██████████| 113/113 [00:00<00:00, 301.33batch/s, train_mean_loss=1.126027]\n",
      "Epoch 232/243: 100%|██████████| 113/113 [00:00<00:00, 306.47batch/s, train_mean_loss=1.118481]\n",
      "Epoch 233/243: 100%|██████████| 113/113 [00:00<00:00, 241.17batch/s, train_mean_loss=1.115505]\n",
      "Epoch 234/243: 100%|██████████| 113/113 [00:00<00:00, 317.59batch/s, train_mean_loss=1.119419]\n",
      "Epoch 235/243: 100%|██████████| 113/113 [00:00<00:00, 295.34batch/s, train_mean_loss=1.101096]\n",
      "Epoch 236/243: 100%|██████████| 113/113 [00:00<00:00, 321.93batch/s, train_mean_loss=1.084086]\n",
      "Epoch 237/243: 100%|██████████| 113/113 [00:00<00:00, 322.78batch/s, train_mean_loss=1.068280]\n",
      "Epoch 238/243: 100%|██████████| 113/113 [00:00<00:00, 332.28batch/s, train_mean_loss=1.072050]\n",
      "Epoch 239/243: 100%|██████████| 113/113 [00:00<00:00, 329.32batch/s, train_mean_loss=1.059121]\n",
      "Epoch 240/243: 100%|██████████| 113/113 [00:00<00:00, 280.98batch/s, train_mean_loss=1.055761]\n",
      "Epoch 241/243: 100%|██████████| 113/113 [00:00<00:00, 248.07batch/s, train_mean_loss=1.042323]\n",
      "Epoch 242/243: 100%|██████████| 113/113 [00:00<00:00, 236.69batch/s, train_mean_loss=1.038288]\n",
      "Epoch 243/243: 100%|██████████| 113/113 [00:00<00:00, 219.39batch/s, train_mean_loss=1.036205]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_num_samples = len(train)\n",
    "train_num_batches = (train_num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "for epoch in range(CONFIG['EPOCHS']):\n",
    "    ##################################################################TRAIN##################################################################\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "\n",
    "    with tqdm(range(train_num_batches), desc=f\"Epoch {epoch + 1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as t:\n",
    "        for batch_idx in t:\n",
    "            start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "            end_idx = min(start_idx + CONFIG['BATCH_SIZE'], train_num_samples)\n",
    "\n",
    "            # Извлечение батча данных\n",
    "            batch_inputs = train_tensors[start_idx:end_idx]\n",
    "            batch_targets = train_targets[start_idx:end_idx]\n",
    "            \n",
    "            # Обнуление градиентов\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Прямой проход\n",
    "            outputs = model(batch_inputs)\n",
    "\n",
    "            # Вычисление функции потерь\n",
    "            batch_loss = criterion(outputs, batch_targets.unsqueeze(1))\n",
    "\n",
    "            # Обратный проход\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss += batch_loss.item()\n",
    "            t.set_postfix(train_mean_loss=f\"{train_running_loss / (batch_idx + 1):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model, f'{number}.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T19:05:52.564000800Z",
     "start_time": "2024-12-26T19:05:52.545000100Z"
    }
   },
   "id": "5dd66befac09e49e",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6155403,
     "sourceId": 10000346,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5460.653933,
   "end_time": "2024-11-25T06:17:15.604943",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-25T04:46:14.951010",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
