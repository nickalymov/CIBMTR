{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "folder_name = os.path.basename(current_directory)\n",
    "number = folder_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:39.599765400Z",
     "start_time": "2025-01-03T17:26:39.590766300Z"
    }
   },
   "id": "cb2065b8802f8251",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import platform\n",
    "platform_name = platform.system()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:39.642766400Z",
     "start_time": "2025-01-03T17:26:39.600766600Z"
    }
   },
   "id": "c77f23bcf20968b4",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'test_path': 'test.csv',\n",
    "    'train_path': 'train.csv',\n",
    "\n",
    "    'DEVICE' : 'cuda',\n",
    "    'SEED' : 42,\n",
    "}\n",
    "if platform_name == 'Windows':\n",
    "    CONFIG['data_main'] = 'C:/Users/Николай/PycharmProjects/CIBMTR/D.Data/main/'\n",
    "    CONFIG['model_path'] = f\"{number}_model.pkl\"\n",
    "else:\n",
    "    CONFIG['data_main'] = '/kaggle/input/equity-post-HCT-survival-predictions/'\n",
    "    CONFIG['model_path'] = \"/kaggle/input/2.1.18_model.pkl/other/default/1/2.1.18_model.pkl\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:39.643764700Z",
     "start_time": "2025-01-03T17:26:39.617767500Z"
    }
   },
   "id": "9174032d882584ac",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import joblib "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:39.655764800Z",
     "start_time": "2025-01-03T17:26:39.631766200Z"
    }
   },
   "id": "b015da9f4c673f76",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_exp = pd.read_csv(f\"{CONFIG['data_main']}data_dictionary.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:39.664764800Z",
     "start_time": "2025-01-03T17:26:39.647764900Z"
    }
   },
   "id": "e218515f86450cb5",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{CONFIG['data_main']}{CONFIG['train_path']}\")\n",
    "train[['sex_1', 'sex_2']] = train['sex_match'].str.split('-', expand=True)\n",
    "train.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "num_columns = []\n",
    "for i, row in data_exp.iterrows():\n",
    "    if row['type'] == 'Numerical':\n",
    "        num_columns.append(row['variable'])\n",
    "num_columns.append('efs')\n",
    "cat_columns = [col for col in train.columns if col not in num_columns]\n",
    "num_columns.remove('efs')\n",
    "num_columns.remove('efs_time')\n",
    "na_num_columns = []\n",
    "for col in num_columns:\n",
    "    train[f\"{col}_nan\"] = train[col].isna().astype(int)\n",
    "    train[f\"{col}_nan\"] = train[col].isna().astype(int)\n",
    "    na_num_columns.append(f\"{col}_nan\")\n",
    "    \n",
    "num_columns.extend(na_num_columns)\n",
    "\n",
    "for col in train[cat_columns].columns:\n",
    "    train[col] = train[col].astype(str)\n",
    "    j_ch = ',[]{}:\"\\\\<'  # набор символов для удаления\n",
    "    for ch in j_ch:\n",
    "        train[col] = train[col].apply(lambda x: str(x).replace(ch, ''))\n",
    "train_one_hot = pd.get_dummies(train[cat_columns])\n",
    "cat_columns = list(train_one_hot.columns)\n",
    "train_one_hot = pd.concat([train_one_hot, train[num_columns]], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:41.251840600Z",
     "start_time": "2025-01-03T17:26:39.661766800Z"
    }
   },
   "id": "214abe3370778cbd",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n",
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_12844\\1408835055.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_one_hot[col] = False\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(f\"{CONFIG['data_main']}test.csv\")\n",
    "test[['sex_1', 'sex_2']] = test['sex_match'].str.split('-', expand=True)\n",
    "num_columns = []\n",
    "for i, row in data_exp.iterrows():\n",
    "    if row['type'] == 'Numerical':\n",
    "        num_columns.append(row['variable'])\n",
    "num_columns.append('efs')\n",
    "cat_columns = [col for col in test.columns if col not in num_columns]\n",
    "num_columns.remove('efs')\n",
    "num_columns.remove('efs_time')\n",
    "\n",
    "na_num_columns = []\n",
    "for col in num_columns:\n",
    "    test[f\"{col}_nan\"] = test[col].isna().astype(int)\n",
    "    test[f\"{col}_nan\"] = test[col].isna().astype(int)\n",
    "    na_num_columns.append(f\"{col}_nan\")\n",
    "    \n",
    "num_columns.extend(na_num_columns)\n",
    "\n",
    "for col in test[cat_columns].columns:\n",
    "    test[col] = test[col].astype(str)\n",
    "    j_ch = ',[]{}:\"\\\\<' \n",
    "    for ch in j_ch:\n",
    "        test[col] = test[col].apply(lambda x: str(x).replace(ch, ''))\n",
    "test_one_hot = pd.get_dummies(test[cat_columns])\n",
    "test_one_hot = pd.concat([test_one_hot, test[num_columns]], axis=1)\n",
    "\n",
    "missing_columns = set(train_one_hot.columns) - set(test_one_hot.columns)\n",
    "for col in missing_columns:\n",
    "    test_one_hot[col] = False\n",
    "    \n",
    "drop_cols = ['hla_match_dqb1_low_nan',\n",
    " 'karnofsky_score_nan',\n",
    " 'hla_low_res_8_nan',\n",
    " 'comorbidity_score_nan',\n",
    " 'hla_match_b_high_nan',\n",
    " 'hla_match_a_low_nan',\n",
    " 'hla_match_drb1_high_nan',\n",
    " 'age_at_hct_nan',\n",
    " 'hla_match_b_low_nan',\n",
    " 'donor_age_nan',\n",
    " 'hla_match_a_high_nan',\n",
    " 'year_hct_nan',\n",
    " 'hla_high_res_6_nan',\n",
    " 'hla_match_drb1_low_nan',\n",
    " 'hla_match_c_low_nan',\n",
    " 'hla_nmdp_6_nan',\n",
    " 'hla_match_dqb1_high_nan',\n",
    " 'hla_high_res_10_nan',\n",
    " 'hla_low_res_6_nan',\n",
    " 'hla_high_res_8_nan',\n",
    " 'hla_match_c_high_nan',\n",
    " 'gvhd_proph_FK+- others(not MMFMTX)',\n",
    " 'graft_type_Peripheral blood',\n",
    " 'prod_type_PB',\n",
    " 'hla_low_res_10_nan']\n",
    "drop_cols_2 = ['sex_1_F',\n",
    " 'sex_2_F',\n",
    " 'tce_match_HvG non-permissive',\n",
    " 'prim_disease_hct_PCD',\n",
    " 'dri_score_Very high',\n",
    " 'tce_imm_match_H/B',\n",
    " 'pulm_severe_nan',\n",
    " 'cyto_score_Other',\n",
    " 'renal_issue_No',\n",
    " 'diabetes_nan',\n",
    " 'vent_hist_nan',\n",
    " 'sex_1_M',\n",
    " 'renal_issue_nan',\n",
    " 'dri_score_nan',\n",
    " 'hepatic_severe_Not done',\n",
    " 'dri_score_Intermediate - TED AML case missing cytogenetics',\n",
    " 'gvhd_proph_nan',\n",
    " 'tce_div_match_Bi-directional non-permissive',\n",
    " 'prim_disease_hct_AI',\n",
    " 'peptic_ulcer_nan',\n",
    " 'gvhd_proph_Other GVHD Prophylaxis',\n",
    " 'peptic_ulcer_Yes',\n",
    " 'rheum_issue_nan',\n",
    " 'psych_disturb_nan',\n",
    " 'psych_disturb_Not done',\n",
    " 'sex_2_M',\n",
    " 'ethnicity_Non-resident of the U.S.',\n",
    " 'cardiac_Not done',\n",
    " 'rheum_issue_Not done',\n",
    " 'dri_score_N/A - disease not classifiable',\n",
    " 'pulm_severe_Not done',\n",
    " 'conditioning_intensity_No drugs reported',\n",
    " 'cyto_score_Normal',\n",
    " 'hepatic_severe_nan',\n",
    " 'obesity_Not done',\n",
    " 'tbi_status_TBI +- Other -cGy unknown dose',\n",
    " 'pulm_moderate_Not done',\n",
    " 'tbi_status_TBI +- Other -cGy single',\n",
    " 'renal_issue_Yes',\n",
    " 'prim_disease_hct_Other leukemia',\n",
    " 'tbi_status_TBI +- Other -cGy fractionated',\n",
    " 'gvhd_proph_CSA + MTX +- others(not MMFFK)',\n",
    " 'prim_disease_hct_Solid tumor',\n",
    " 'gvhd_proph_TDEPLETION +- other',\n",
    " 'prim_disease_hct_HD',\n",
    " 'gvhd_proph_CDselect alone',\n",
    " 'gvhd_proph_No GvHD Prophylaxis',\n",
    " 'renal_issue_Not done',\n",
    " 'hepatic_mild_Not done',\n",
    " 'sex_match_nan',\n",
    " 'prim_disease_hct_Other acute leukemia',\n",
    " 'prim_disease_hct_CML',\n",
    " 'gvhd_proph_CSA alone',\n",
    " 'sex_1_nan',\n",
    " 'tbi_status_TBI +- Other unknown dose',\n",
    " 'prim_disease_hct_IMD',\n",
    " 'gvhd_proph_Parent Q = yes but no agent',\n",
    " 'conditioning_intensity_N/A F(pre-TED) not submitted',\n",
    " 'tce_imm_match_P/H',\n",
    " 'sex_2_nan',\n",
    " 'cyto_score_Not tested',\n",
    " 'gvhd_proph_CDselect +- other',\n",
    " 'dri_score_Missing disease status',\n",
    " 'gvhd_proph_CSA +- others(not FKMMFMTX)',\n",
    " 'tce_imm_match_P/G',\n",
    " 'tce_imm_match_P/B']\n",
    "drop_cols.extend(drop_cols_2)\n",
    "train_one_hot.drop(columns=drop_cols, inplace=True)\n",
    "test_one_hot.drop(columns=drop_cols, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:41.331071500Z",
     "start_time": "2025-01-03T17:26:41.258914100Z"
    }
   },
   "id": "ac0fb31bb289572f",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_one_hot = test_one_hot[train_one_hot.columns]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:41.372984Z",
     "start_time": "2025-01-03T17:26:41.334060600Z"
    }
   },
   "id": "c716f6fbaf1ed7dc",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_cat = joblib.load(CONFIG['model_path'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:41.662983400Z",
     "start_time": "2025-01-03T17:26:41.348049300Z"
    }
   },
   "id": "c24795b246f48d95",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preds_test = final_cat.predict(test_one_hot)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:41.680051600Z",
     "start_time": "2025-01-03T17:26:41.664082800Z"
    }
   },
   "id": "887fcb1c03c25912",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_pred = test[['ID']].copy(deep=True)\n",
    "y_pred[\"prediction\"] = preds_test\n",
    "y_pred.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:41.698965200Z",
     "start_time": "2025-01-03T17:26:41.680978900Z"
    }
   },
   "id": "903cca0ce259731a",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      ID  prediction\n0  28800    0.441868\n1  28801    0.636648\n2  28802    0.382843",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28800</td>\n      <td>0.441868</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28801</td>\n      <td>0.636648</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28802</td>\n      <td>0.382843</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:41.713961500Z",
     "start_time": "2025-01-03T17:26:41.698965200Z"
    }
   },
   "id": "c9936d3144e3694e",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T17:26:41.758974400Z",
     "start_time": "2025-01-03T17:26:41.712963400Z"
    }
   },
   "id": "18cd3c105f40a676",
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
